{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets sentencepiece --quiet\n",
        "\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "\n",
        "# Model and tokenizer\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-de\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Small data set (only 3 examples)\n",
        "data = [\n",
        "    {\"en\": \"The patient has a fever.\", \"de\": \"Der Patient hat Fieber.\"},\n",
        "    {\"en\": \"Take this medicine twice a day.\", \"de\": \"Nehmen Sie dieses Medikament zweimal täglich.\"},\n",
        "    {\"en\": \"You need to rest.\", \"de\": \"Sie müssen sich ausruhen.\"}\n",
        "]\n",
        "dataset = Dataset.from_list(data)\n",
        "\n",
        "# Tokenizer\n",
        "def tokenize(batch):\n",
        "    inputs = tokenizer(batch['en'], padding=\"max_length\", truncation=True, max_length=64)\n",
        "    targets = tokenizer(batch['de'], padding=\"max_length\", truncation=True, max_length=64)\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
        "\n",
        "# Training options\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=2,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=1,\n",
        "    predict_with_generate=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=1,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Sample before training\n",
        "def translate(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "    translated = model.generate(**inputs)\n",
        "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Before fine-tuning:\")\n",
        "print(\"English: I have a math exam tomorrow.\")\n",
        "print(\"German:\", translate(\"I have a math exam tomorrow.\"))\n",
        "\n",
        "# Training\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\nAfter fine-tuning:\")\n",
        "print(\"English: I have a math exam tomorrow.\")\n",
        "print(\"German:\", translate(\"I have a math exam tomorrow.\"))\n"
      ],
      "metadata": {
        "id": "VN06bTDtUACC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}